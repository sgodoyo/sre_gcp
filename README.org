:PROPERTIES:
:GPTEL_MODEL: gpt-3.5-turbo
:GPTEL_BOUNDS: ((40346 . 40713) (40820 . 42053))
:END:
#+TITLE: Ejercicio práctico para el puesto de SRE
#+SUBTITLE: Google Cloud Platform
#+AUTHOR: Sebastian Godoy Olivares
#+EMAIL: shackleto@riseup.net
#+DATE: 
#+DESCRIPTION: Practico SRE
#+KEYWORDS: devops, gcp
#+LANGUAGE: es
#+OPTIONS: toc:nil num:nil
#+CATEGORY: devops
#+TAGS: devops, gcp, cloud, iac

* Objetivo:
Demostrar de forma práctica el conocimiento de automatización y configuración de
infraestructura.

** Herramientas a evaluar:
- Packer
- Ansible
- Terraform
- Terragrunt(opcional)

Utilizando una cuenta gratuita de GCP realizar la automatización del siguiente
ejercicio

[[diagrama.png]]

Utilizando la VPC y redes por defecto de la cuenta realizar los scripts de
automatización para los siguientes componentes:
- Cloud Load Balancer
- Cloud DNS
- Bastion
- GKE Cluster
- Container Registry
- Cloud SQL (postgresql)

** Adicional realizar el deploy de una aplicación:
- Lenguaje Opcional
- Que consuma algún dato de la base

Deseable pero no requerido, implementar una malla de servicios ISTIO

** Entregable:
Repositorio Github público con los script, tiempo disponible 24 horas

* Configuración previa
** DONE Crear una cuenta de Google Cloud Platform:
  Si aún no tienes una, deberás crear una cuenta en Google Cloud Platform. Google ofrece una prueba gratuita para nuevos usuarios.

** DONE Crear un proyecto:
  Los recursos de GCP están organizados en proyectos. Desde la consola de GCP, puedes crear un nuevo proyecto en el que trabajar.

** DONE Habilitar las APIs necesarias:
  Para este ejercicio, es posible que necesites habilitar las APIs de *Compute Engine*, *Kubernetes Engine*, *Cloud SQL* y otras APIs relacionadas. Esto puede hacerse desde la consola de GCP en la sección "APIs & Services > Library".

** DONE Configurar el SDK de Google Cloud:
  Descarga e instala el SDK de Google Cloud en tu máquina local. Esto te permitirá interactuar con tus recursos de GCP desde la línea de comandos.

** DONE Después de la instalación, autentícate ejecutando =gcloud auth login= y sigue las instrucciones.

** DONE Establece tu proyecto predeterminado con =gcloud config set project PROJECT_ID= reemplazando PROJECT_ID por el ID de tu proyecto.

**  DONE Crear un servicio de cuenta:
Para interactuar con GCP desde Packer, Ansible, Terraform y Terragrunt, necesitarás autenticarte. La forma recomendada de hacerlo es a través de una cuenta de servicio.

- Desde la consola de GCP, ve a "IAM & Admin > Service Accounts" y crea una nueva cuenta de servicio.
- Descarga la clave de la cuenta de servicio en formato JSON. (Guarda en un directorio privado y protegido)
- Establece la variable de entorno GOOGLE_APPLICATION_CREDENTIALS en tu máquina local para que apunte a la ruta del archivo de clave JSON.

#+begin_src bash
export GOOGLE_APPLICATION_CREDENTIALS="/ruta/al/archivo.json"
#+end_src

** DONE Configurar permisos:
Asegúrate de que la cuenta de servicio que has creado tiene los permisos necesarios para crear y administrar los recursos que necesitas. Esto puede incluir roles como "Compute Admin", "Kubernetes Engine Admin", "Cloud SQL Admin", y más, dependiendo de tus necesidades.

* TODO Desarrollo
** DONE Automatización con Packer y Ansible.
Estas herramientas se utilizarán para la creación y configuración de la máquina de Bastion.

*** Install plugins for packer

#+begin_src bash
packer plugins install github.com/hashicorp/googlecompute
packer plugins install github.com/hashicorp/ansible
#+end_src

*** Conocer proyectos IDs, zonas e imágenes disponibles.
#+begin_src bash
gcloud projects list
gcloud compute zones list
gcloud compute images list
gcloud compute images list | grep debian
gcloud compute machine-types list --filter="zone:(us-central1-a)"
#+end_src

*** Packer configuration - bastion.json
#+begin_src json
{
  "builders": [
    {
      "type": "googlecompute",
      "project_id": "{{user `gcp_project_id`}}",
      "source_image_family": "{{user `gcp_image_select`}}",
      "ssh_username": "packer",
      "zone": "{{user `gcp_zone`}}",
      "instance_name": "bastion-temp",
      "machine_type": "e2-micro"
    }
  ],
  "provisioners": [
    {
      "type": "ansible",
      "playbook_file": "./bastion_playbook.yml"
    }
  ]
}
#+end_src

*** Ansible playbook - bastion_playbook.yml
#+begin_src yaml
---
- hosts: all
  become: yes
  vars:
    packages:
      - emacs
      - git
  tasks:
    - name: Update all packages
      apt:
        upgrade: dist
        update_cache: yes
        cache_valid_time: 3600

    - name: Install necessary packages
      apt:
        name: "{{ packages }}"
        state: present
        update_cache: yes
#+end_src

*** Para construir la imagen:
#+begin_src bash
packer build -var 'gcp_project_id=YOUR_PROJECT_ID' -var 'gcp_zone=YOUR_ZONE' bastion.json
#+end_src

**** Backtrace
#+begin_src bash
packer build -var 'gcp_project_id=sre-gcp-394115' -var 'gcp_image_select=debian-12' -var 'gcp_zone=us-central1-c' bastion.json

googlecompute: output will be in this color.

==> googlecompute: Checking image does not exist...
==> googlecompute: Creating temporary RSA SSH key for instance...
==> googlecompute: no persistent disk to create
==> googlecompute: Using image: debian-12-bookworm-v20230724
==> googlecompute: Creating instance...
    googlecompute: Loading zone: us-central1-c
    googlecompute: Loading machine type: e2-micro
    googlecompute: Requesting instance creation...
    googlecompute: Waiting for creation operation to complete...
    googlecompute: Instance has been created!
==> googlecompute: Waiting for the instance to become running...
    googlecompute: IP: 34.133.243.168
==> googlecompute: Using SSH communicator to connect: 34.133.243.168
==> googlecompute: Waiting for SSH to become available...
==> googlecompute: Connected to SSH!
==> googlecompute: Provisioning with Ansible...
    googlecompute: Setting up proxy adapter for Ansible....
==> googlecompute: Executing Ansible: ansible-playbook -e packer_build_name="googlecompute" -e packer_builder_type=googlecompute --ssh-extra-args '-o IdentitiesOnly=yes' -e ansible_ssh_private_key_file=/tmp/ansible-key2859791327 -i /tmp/packer-provisioner-ansible3150707614 /home/shackleton/Proyectos/SRE_GCP/sre_gcp/bastion_playbook.yml
    googlecompute:
    googlecompute: PLAY [all] *********************************************************************
    googlecompute:
    googlecompute: TASK [Gathering Facts] *********************************************************
    googlecompute: ok: [default]
    googlecompute:
    googlecompute: TASK [Update all packages] *****************************************************
    googlecompute: changed: [default]
    googlecompute:
    googlecompute: TASK [Install necessary packages] **********************************************
    googlecompute: changed: [default]
    googlecompute:
    googlecompute: PLAY RECAP *********************************************************************
    googlecompute: default                    : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
    googlecompute:
==> googlecompute: Deleting instance...
    googlecompute: Instance has been deleted!
==> googlecompute: Creating image...
==> googlecompute: Deleting disk...
    googlecompute: Disk has been deleted!
Build 'googlecompute' finished after 23 minutes 34 seconds.

==> Wait completed after 23 minutes 34 seconds

==> Builds finished. The artifacts of successful builds are:
--> googlecompute: A disk image was created: packer-1690487605
#+end_src

- En primer lugar, Packer verifica que la imagen que estás intentando crear no existe ya. Si existiera, Packer no continuaría con la build.
- Luego, Packer crea una clave SSH temporal para poder conectarse a la instancia que va a crear en Google Cloud Platform (GCP).
- Packer selecciona la imagen base debian-12-bookworm-v20230724 y crea la instancia en la zona us-central1-c con el tipo de máquina e2-micro.
- Después de que la instancia ha sido creada y está en ejecución, Packer se conecta a la instancia mediante SSH.
- Una vez conectado, Packer ejecuta el provisionador, en este caso Ansible, para configurar la instancia según tu playbook bastion_playbook.yml. Según la salida, Ansible ha actualizado los paquetes e instalado los paquetes necesarios.
- Después de que la configuración ha finalizado con éxito, Packer elimina la instancia.

A continuación, Packer crea la imagen a partir del estado del disco de la instancia justo después de que se haya ejecutado el provisionador. Finalmente, Packer elimina el disco temporal.

El resultado es una nueva imagen llamada packer-1690487605 que puedes usar para lanzar nuevas instancias con la configuración definida en tu playbook de Ansible.
** DONE Automatización con Terraform.
Esto se utilizará para configurar los otros componentes de la infraestructura. Configurar el Cloud Load Balancer, Cloud DNS, GKE Cluster, Container Registry y Cloud SQL.
*** main.tf
#+begin_src terraform
provider "google" {
  project = var.project_id
  region  = var.region
  zone    = var.zone
}

# GKE Cluster
resource "google_container_cluster" "small_cluster" {
  name                     = "small-cluster"
  location                 = var.region
  initial_node_count       = 1
  remove_default_node_pool = true

  master_auth {
    client_certificate_config {
      issue_client_certificate = false
    }
  }

  master_authorized_networks_config {
    cidr_blocks {
      cidr_block   = "0.0.0.0/0"
      display_name = "Any IP"
    }
  }
}

# GKE Node Pool
resource "google_container_node_pool" "primary" {
  name       = "small-pool"
  location   = var.region
  cluster    = google_container_cluster.small_cluster.name
  node_count = 1

  node_config {
    preemptible  = true
    machine_type = "e2-micro"
    disk_size_gb = 20

    oauth_scopes = [
      "https://www.googleapis.com/auth/logging.write",
      "https://www.googleapis.com/auth/monitoring",
    ]
  }

  autoscaling {
    min_node_count = 1
    max_node_count = 2
  }

  management {
    auto_repair  = true
    auto_upgrade = true
  }
}

# Cloud SQL Database
resource "google_sql_database_instance" "default" {
  name             = "database"
  region           = var.region
  database_version = "POSTGRES_13"

  settings {
    tier = "db-f1-micro"
  }
}

resource "google_sql_database" "default" {
  name     = "my-database"
  instance = google_sql_database_instance.default.name
}

# Load Balancer
resource "google_compute_forwarding_rule" "default" {
  name                  = "lb-rule"
  load_balancing_scheme = "EXTERNAL"
  port_range            = "80"
  target                = google_compute_target_pool.default.self_link
}

resource "google_compute_target_pool" "default" {
  name = "target-pool"
  instances = [
    google_compute_instance.bastion_host.self_link
  ]
}

# DNS Record
resource "google_dns_record_set" "www" {
  name         = "www.your-domain.com."
  type         = "A"
  ttl          = 300
  managed_zone = "your-zone-name"
  rrdatas      = [google_compute_forwarding_rule.default.IP_address]
}

# Bastion Host
resource "google_compute_instance" "bastion_host" {
  name         = "bastion"
  machine_type = "e1-micro"
  zone         = var.zone

  boot_disk {
    initialize_params {
      image = var.bastion_image
    }
  }

  network_interface {
    network = "default"

    access_config {
      // Ephemeral IP
    }
  }

  service_account {
    scopes = [
      "https://www.googleapis.com/auth/logging.write",
      "https://www.googleapis.com/auth/monitoring",
      "https://www.googleapis.com/auth/pubsub",
      "https://www.googleapis.com/auth/service.management.readonly",
      "https://www.googleapis.com/auth/servicecontrol",
      "https://www.googleapis.com/auth/trace.append",
    ]
  }
}
#+end_src

*** Terraform init
#+begin_src bash
terraform init

Initializing the backend...

Initializing provider plugins...
- Finding latest version of hashicorp/google...
- Installing hashicorp/google v4.75.1...
- Installed hashicorp/google v4.75.1 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
#+end_src

#+begin_src bash
gcloud auth application-default login
#+end_src

*** terraform plan
#+begin_src bash
terraform plan

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_backend_service.webservers_backend will be created
  + resource "google_compute_backend_service" "webservers_backend" {
      + connection_draining_timeout_sec = 300
      + creation_timestamp              = (known after apply)
      + fingerprint                     = (known after apply)
      + generated_id                    = (known after apply)
      + health_checks                   = (known after apply)
      + id                              = (known after apply)
      + load_balancing_scheme           = "EXTERNAL"
      + name                            = "webservers-backend"
      + port_name                       = (known after apply)
      + project                         = (known after apply)
      + protocol                        = (known after apply)
      + self_link                       = (known after apply)
      + session_affinity                = (known after apply)
      + timeout_sec                     = (known after apply)

      + cdn_policy {
          + cache_mode                   = (known after apply)
          + client_ttl                   = (known after apply)
          + default_ttl                  = (known after apply)
          + max_ttl                      = (known after apply)
          + negative_caching             = (known after apply)
          + serve_while_stale            = (known after apply)
          + signed_url_cache_max_age_sec = (known after apply)

          + bypass_cache_on_request_headers {
              + header_name = (known after apply)
            }

          + cache_key_policy {
              + include_host           = (known after apply)
              + include_http_headers   = (known after apply)
              + include_named_cookies  = (known after apply)
              + include_protocol       = (known after apply)
              + include_query_string   = (known after apply)
              + query_string_blacklist = (known after apply)
              + query_string_whitelist = (known after apply)
            }

          + negative_caching_policy {
              + code = (known after apply)
              + ttl  = (known after apply)
            }
        }

      + log_config {
          + enable      = (known after apply)
          + sample_rate = (known after apply)
        }
    }

  # google_compute_global_forwarding_rule.http will be created
  + resource "google_compute_global_forwarding_rule" "http" {
      + base_forwarding_rule  = (known after apply)
      + id                    = (known after apply)
      + ip_address            = (known after apply)
      + ip_protocol           = (known after apply)
      + label_fingerprint     = (known after apply)
      + load_balancing_scheme = "EXTERNAL"
      + name                  = "http-content-rule"
      + network               = (known after apply)
      + port_range            = "80"
      + project               = (known after apply)
      + psc_connection_id     = (known after apply)
      + psc_connection_status = (known after apply)
      + self_link             = (known after apply)
      + target                = (known after apply)
    }

  # google_compute_health_check.default will be created
  + resource "google_compute_health_check" "default" {
      + check_interval_sec  = 30
      + creation_timestamp  = (known after apply)
      + healthy_threshold   = 2
      + id                  = (known after apply)
      + name                = "default"
      + project             = (known after apply)
      + self_link           = (known after apply)
      + timeout_sec         = 5
      + type                = (known after apply)
      + unhealthy_threshold = 10

      + http_health_check {
          + port         = 80
          + proxy_header = "NONE"
          + request_path = "/"
        }

      + log_config {
          + enable = (known after apply)
        }
    }

  # google_compute_instance_group.webservers will be created
  + resource "google_compute_instance_group" "webservers" {
      + id        = (known after apply)
      + instances = (known after apply)
      + name      = "web-instances"
      + network   = (known after apply)
      + project   = (known after apply)
      + self_link = (known after apply)
      + size      = (known after apply)
      + zone      = (known after apply)
    }

  # google_compute_network.vpc_network will be created
  + resource "google_compute_network" "vpc_network" {
      + auto_create_subnetworks                   = true
      + delete_default_routes_on_create           = false
      + gateway_ipv4                              = (known after apply)
      + id                                        = (known after apply)
      + internal_ipv6_range                       = (known after apply)
      + mtu                                       = (known after apply)
      + name                                      = "my-vpc"
      + network_firewall_policy_enforcement_order = "AFTER_CLASSIC_FIREWALL"
      + project                                   = (known after apply)
      + routing_mode                              = (known after apply)
      + self_link                                 = (known after apply)
    }

  # google_compute_target_http_proxy.http will be created
  + resource "google_compute_target_http_proxy" "http" {
      + creation_timestamp = (known after apply)
      + id                 = (known after apply)
      + name               = "http-lb-proxy"
      + project            = (known after apply)
      + proxy_bind         = (known after apply)
      + proxy_id           = (known after apply)
      + self_link          = (known after apply)
      + url_map            = (known after apply)
    }

  # google_compute_url_map.urlmap will be created
  + resource "google_compute_url_map" "urlmap" {
      + creation_timestamp = (known after apply)
      + default_service    = (known after apply)
      + fingerprint        = (known after apply)
      + id                 = (known after apply)
      + map_id             = (known after apply)
      + name               = "lb-url-map"
      + project            = (known after apply)
      + self_link          = (known after apply)
    }

  # google_container_cluster.cluster will be created
  + resource "google_container_cluster" "cluster" {
      + cluster_ipv4_cidr           = (known after apply)
      + datapath_provider           = (known after apply)
      + default_max_pods_per_node   = (known after apply)
      + enable_binary_authorization = false
      + enable_intranode_visibility = (known after apply)
      + enable_kubernetes_alpha     = false
      + enable_l4_ilb_subsetting    = false
      + enable_legacy_abac          = false
      + enable_shielded_nodes       = true
      + endpoint                    = (known after apply)
      + id                          = (known after apply)
      + initial_node_count          = 3
      + label_fingerprint           = (known after apply)
      + location                    = "us-central1"
      + logging_service             = (known after apply)
      + master_version              = (known after apply)
      + monitoring_service          = (known after apply)
      + name                        = "my-cluster"
      + network                     = "default"
      + networking_mode             = (known after apply)
      + node_locations              = (known after apply)
      + node_version                = (known after apply)
      + operation                   = (known after apply)
      + private_ipv6_google_access  = (known after apply)
      + project                     = (known after apply)
      + self_link                   = (known after apply)
      + services_ipv4_cidr          = (known after apply)
      + subnetwork                  = (known after apply)
      + tpu_ipv4_cidr_block         = (known after apply)

      + addons_config {
          + cloudrun_config {
              + disabled           = (known after apply)
              + load_balancer_type = (known after apply)
            }

          + config_connector_config {
              + enabled = (known after apply)
            }

          + dns_cache_config {
              + enabled = (known after apply)
            }

          + gce_persistent_disk_csi_driver_config {
              + enabled = (known after apply)
            }

          + gcp_filestore_csi_driver_config {
              + enabled = (known after apply)
            }

          + gke_backup_agent_config {
              + enabled = (known after apply)
            }

          + horizontal_pod_autoscaling {
              + disabled = (known after apply)
            }

          + http_load_balancing {
              + disabled = (known after apply)
            }

          + network_policy_config {
              + disabled = (known after apply)
            }
        }

      + authenticator_groups_config {
          + security_group = (known after apply)
        }

      + cluster_autoscaling {
          + enabled = (known after apply)

          + auto_provisioning_defaults {
              + boot_disk_kms_key = (known after apply)
              + disk_size         = (known after apply)
              + disk_type         = (known after apply)
              + image_type        = (known after apply)
              + min_cpu_platform  = (known after apply)
              + oauth_scopes      = (known after apply)
              + service_account   = (known after apply)

              + management {
                  + auto_repair     = (known after apply)
                  + auto_upgrade    = (known after apply)
                  + upgrade_options = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + upgrade_settings {
                  + max_surge       = (known after apply)
                  + max_unavailable = (known after apply)
                  + strategy        = (known after apply)

                  + blue_green_settings {
                      + node_pool_soak_duration = (known after apply)

                      + standard_rollout_policy {
                          + batch_node_count    = (known after apply)
                          + batch_percentage    = (known after apply)
                          + batch_soak_duration = (known after apply)
                        }
                    }
                }
            }

          + resource_limits {
              + maximum       = (known after apply)
              + minimum       = (known after apply)
              + resource_type = (known after apply)
            }
        }

      + confidential_nodes {
          + enabled = (known after apply)
        }

      + cost_management_config {
          + enabled = (known after apply)
        }

      + database_encryption {
          + key_name = (known after apply)
          + state    = (known after apply)
        }

      + default_snat_status {
          + disabled = (known after apply)
        }

      + gateway_api_config {
          + channel = (known after apply)
        }

      + ip_allocation_policy {
          + cluster_ipv4_cidr_block       = (known after apply)
          + cluster_secondary_range_name  = (known after apply)
          + services_ipv4_cidr_block      = (known after apply)
          + services_secondary_range_name = (known after apply)
          + stack_type                    = (known after apply)

          + pod_cidr_overprovision_config {
              + disabled = (known after apply)
            }
        }

      + logging_config {
          + enable_components = (known after apply)
        }

      + master_auth {
          + client_certificate     = (known after apply)
          + client_key             = (sensitive value)
          + cluster_ca_certificate = (known after apply)

          + client_certificate_config {
              + issue_client_certificate = false
            }
        }

      + master_authorized_networks_config {
          + gcp_public_cidrs_access_enabled = (known after apply)

          + cidr_blocks {
              + cidr_block   = (known after apply)
              + display_name = (known after apply)
            }
        }

      + mesh_certificates {
          + enable_certificates = (known after apply)
        }

      + monitoring_config {
          + enable_components = (known after apply)

          + managed_prometheus {
              + enabled = (known after apply)
            }
        }

      + node_config {
          + boot_disk_kms_key = (known after apply)
          + disk_size_gb      = (known after apply)
          + disk_type         = (known after apply)
          + guest_accelerator = (known after apply)
          + image_type        = (known after apply)
          + labels            = (known after apply)
          + local_ssd_count   = (known after apply)
          + logging_variant   = (known after apply)
          + machine_type      = (known after apply)
          + metadata          = (known after apply)
          + min_cpu_platform  = (known after apply)
          + node_group        = (known after apply)
          + oauth_scopes      = (known after apply)
          + preemptible       = (known after apply)
          + resource_labels   = (known after apply)
          + service_account   = (known after apply)
          + spot              = (known after apply)
          + tags              = (known after apply)
          + taint             = (known after apply)

          + advanced_machine_features {
              + threads_per_core = (known after apply)
            }

          + ephemeral_storage_local_ssd_config {
              + local_ssd_count = (known after apply)
            }

          + gcfs_config {
              + enabled = (known after apply)
            }

          + gvnic {
              + enabled = (known after apply)
            }

          + kubelet_config {
              + cpu_cfs_quota        = (known after apply)
              + cpu_cfs_quota_period = (known after apply)
              + cpu_manager_policy   = (known after apply)
              + pod_pids_limit       = (known after apply)
            }

          + linux_node_config {
              + sysctls = (known after apply)
            }

          + local_nvme_ssd_block_config {
              + local_ssd_count = (known after apply)
            }

          + reservation_affinity {
              + consume_reservation_type = (known after apply)
              + key                      = (known after apply)
              + values                   = (known after apply)
            }

          + shielded_instance_config {
              + enable_integrity_monitoring = (known after apply)
              + enable_secure_boot          = (known after apply)
            }

          + sole_tenant_config {
              + node_affinity {
                  + key      = (known after apply)
                  + operator = (known after apply)
                  + values   = (known after apply)
                }
            }

          + workload_metadata_config {
              + mode = (known after apply)
            }
        }

      + node_pool {
          + initial_node_count          = (known after apply)
          + instance_group_urls         = (known after apply)
          + managed_instance_group_urls = (known after apply)
          + max_pods_per_node           = (known after apply)
          + name                        = (known after apply)
          + name_prefix                 = (known after apply)
          + node_count                  = (known after apply)
          + node_locations              = (known after apply)
          + version                     = (known after apply)

          + autoscaling {
              + location_policy      = (known after apply)
              + max_node_count       = (known after apply)
              + min_node_count       = (known after apply)
              + total_max_node_count = (known after apply)
              + total_min_node_count = (known after apply)
            }

          + management {
              + auto_repair  = (known after apply)
              + auto_upgrade = (known after apply)
            }

          + network_config {
              + create_pod_range     = (known after apply)
              + enable_private_nodes = (known after apply)
              + pod_ipv4_cidr_block  = (known after apply)
              + pod_range            = (known after apply)

              + pod_cidr_overprovision_config {
                  + disabled = (known after apply)
                }
            }

          + node_config {
              + boot_disk_kms_key = (known after apply)
              + disk_size_gb      = (known after apply)
              + disk_type         = (known after apply)
              + guest_accelerator = (known after apply)
              + image_type        = (known after apply)
              + labels            = (known after apply)
              + local_ssd_count   = (known after apply)
              + logging_variant   = (known after apply)
              + machine_type      = (known after apply)
              + metadata          = (known after apply)
              + min_cpu_platform  = (known after apply)
              + node_group        = (known after apply)
              + oauth_scopes      = (known after apply)
              + preemptible       = (known after apply)
              + resource_labels   = (known after apply)
              + service_account   = (known after apply)
              + spot              = (known after apply)
              + tags              = (known after apply)
              + taint             = (known after apply)

              + advanced_machine_features {
                  + threads_per_core = (known after apply)
                }

              + ephemeral_storage_local_ssd_config {
                  + local_ssd_count = (known after apply)
                }

              + gcfs_config {
                  + enabled = (known after apply)
                }

              + gvnic {
                  + enabled = (known after apply)
                }

              + kubelet_config {
                  + cpu_cfs_quota        = (known after apply)
                  + cpu_cfs_quota_period = (known after apply)
                  + cpu_manager_policy   = (known after apply)
                  + pod_pids_limit       = (known after apply)
                }

              + linux_node_config {
                  + sysctls = (known after apply)
                }

              + local_nvme_ssd_block_config {
                  + local_ssd_count = (known after apply)
                }

              + reservation_affinity {
                  + consume_reservation_type = (known after apply)
                  + key                      = (known after apply)
                  + values                   = (known after apply)
                }

              + shielded_instance_config {
                  + enable_integrity_monitoring = (known after apply)
                  + enable_secure_boot          = (known after apply)
                }

              + sole_tenant_config {
                  + node_affinity {
                      + key      = (known after apply)
                      + operator = (known after apply)
                      + values   = (known after apply)
                    }
                }

              + workload_metadata_config {
                  + mode = (known after apply)
                }
            }

          + placement_policy {
              + type = (known after apply)
            }

          + upgrade_settings {
              + max_surge       = (known after apply)
              + max_unavailable = (known after apply)
              + strategy        = (known after apply)

              + blue_green_settings {
                  + node_pool_soak_duration = (known after apply)

                  + standard_rollout_policy {
                      + batch_node_count    = (known after apply)
                      + batch_percentage    = (known after apply)
                      + batch_soak_duration = (known after apply)
                    }
                }
            }
        }

      + node_pool_defaults {
          + node_config_defaults {
              + logging_variant = (known after apply)
            }
        }

      + notification_config {
          + pubsub {
              + enabled = (known after apply)
              + topic   = (known after apply)

              + filter {
                  + event_type = (known after apply)
                }
            }
        }

      + release_channel {
          + channel = (known after apply)
        }

      + security_posture_config {
          + mode               = (known after apply)
          + vulnerability_mode = (known after apply)
        }

      + service_external_ips_config {
          + enabled = (known after apply)
        }

      + vertical_pod_autoscaling {
          + enabled = (known after apply)
        }

      + workload_identity_config {
          + workload_pool = (known after apply)
        }
    }

  # google_container_registry.default will be created
  + resource "google_container_registry" "default" {
      + bucket_self_link = (known after apply)
      + id               = (known after apply)
      + location         = "US"
      + project          = (known after apply)
    }

  # google_dns_managed_zone.dns_zone will be created
  + resource "google_dns_managed_zone" "dns_zone" {
      + creation_time   = (known after apply)
      + description     = "Managed DNS zone for the domain"
      + dns_name        = "mydomain.com."
      + force_destroy   = false
      + id              = (known after apply)
      + managed_zone_id = (known after apply)
      + name            = "dns-zone"
      + name_servers    = (known after apply)
      + project         = (known after apply)
      + visibility      = "public"

      + cloud_logging_config {
          + enable_logging = (known after apply)
        }
    }

  # google_sql_database_instance.master will be created
  + resource "google_sql_database_instance" "master" {
      + available_maintenance_versions = (known after apply)
      + connection_name                = (known after apply)
      + database_version               = "POSTGRES_13"
      + deletion_protection            = true
      + encryption_key_name            = (known after apply)
      + first_ip_address               = (known after apply)
      + id                             = (known after apply)
      + instance_type                  = (known after apply)
      + ip_address                     = (known after apply)
      + maintenance_version            = (known after apply)
      + master_instance_name           = (known after apply)
      + name                           = "master-instance"
      + private_ip_address             = (known after apply)
      + project                        = (known after apply)
      + public_ip_address              = (known after apply)
      + region                         = (known after apply)
      + self_link                      = (known after apply)
      + server_ca_cert                 = (known after apply)
      + service_account_email_address  = (known after apply)

      + replica_configuration {
          + ca_certificate            = (known after apply)
          + client_certificate        = (known after apply)
          + client_key                = (known after apply)
          + connect_retry_interval    = (known after apply)
          + dump_file_path            = (known after apply)
          + failover_target           = (known after apply)
          + master_heartbeat_period   = (known after apply)
          + password                  = (sensitive value)
          + ssl_cipher                = (known after apply)
          + username                  = (known after apply)
          + verify_server_certificate = (known after apply)
        }

      + settings {
          + activation_policy     = "ALWAYS"
          + availability_type     = "ZONAL"
          + connector_enforcement = (known after apply)
          + disk_autoresize       = true
          + disk_autoresize_limit = 0
          + disk_size             = (known after apply)
          + disk_type             = "PD_SSD"
          + pricing_plan          = "PER_USE"
          + tier                  = "db-f1-micro"
          + user_labels           = (known after apply)
          + version               = (known after apply)

          + backup_configuration {
              + binary_log_enabled             = (known after apply)
              + enabled                        = (known after apply)
              + location                       = (known after apply)
              + point_in_time_recovery_enabled = (known after apply)
              + start_time                     = (known after apply)
              + transaction_log_retention_days = (known after apply)

              + backup_retention_settings {
                  + retained_backups = (known after apply)
                  + retention_unit   = (known after apply)
                }
            }

          + ip_configuration {
              + allocated_ip_range                            = (known after apply)
              + enable_private_path_for_google_cloud_services = (known after apply)
              + ipv4_enabled                                  = (known after apply)
              + private_network                               = (known after apply)
              + require_ssl                                   = (known after apply)

              + authorized_networks {
                  + expiration_time = (known after apply)
                  + name            = (known after apply)
                  + value           = (known after apply)
                }
            }

          + location_preference {
              + follow_gae_application = (known after apply)
              + secondary_zone         = (known after apply)
              + zone                   = (known after apply)
            }
        }
    }

Plan: 11 to add, 0 to change, 0 to destroy.



Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run "terraform apply" now.
#+end_src

*** terraform apply
#+begin_src bash
terraform apply --auto-approve
#+end_src
** DONE Contenerizar aplicación.

*** Dockerfile

#+begin_src dockerfile
FROM python:3.9

MAINTAINER Sebastian Godoy Olivares <shackleton@riseup.net>

ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

WORKDIR /app

COPY requirements.txt .

COPY pickle_model.pkl .

RUN pip install --upgrade pip

COPY . .

RUN pip install scikit-learn

RUN pip install -r requirements.txt

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
#+end_src

*** Para compilar la imagen Docker y establecer un nombre para la imagen.

1. Navega a la ubicación donde se encuentra el archivo =Dockerfile= en tu proyecto.

2. Ejecuta el siguiente comando para compilar la imagen:

   #+begin_src 
   docker build -t nombre_imagen .
   #+end_src

***** Compilacion de docker imagen
#+begin_src bash
docker build -t fastapi-app .
docker image ls | grep fastapi-app
#+end_src

*** Registrar imagen docker en container registry de google cloud

1. Asegúrate de tener la imagen Docker compilada en tu entorno de desarrollo.

2. Inicia sesión en tu cuenta de Google Cloud Platform (GCP) utilizando el siguiente comando:
   #+begin_src 
   gcloud auth login
   #+end_src

3. Establece tu proyecto de GCP como proyecto actual utilizando el siguiente comando:
   #+begin_src 
   gcloud config set project <nombre_del_proyecto>
   #+end_src

4. Autentica Docker para usar el registro de contenedores de Google Cloud utilizando el siguiente comando:
   #+begin_src 
   gcloud auth configure-docker
   #+end_src

5. Etiqueta tu imagen Docker para que sea compatible con el registro de contenedores de Google Cloud. Puedes hacerlo utilizando el siguiente comando:
   #+begin_src 
   docker tag <nombre_de_la_imagen>:<etiqueta> gcr.io/<nombre_del_proyecto>/<nombre_de_la_imagen>:<etiqueta>
   #+end_src
   Reemplaza =<nombre_de_la_imagen>= con el nombre de tu imagen y =<etiqueta>= con la etiqueta que desees usar.

6. Finalmente, haz push de tu imagen Docker al registro de contenedores de Google Cloud utilizando el siguiente comando:
   #+begin_src 
   docker push gcr.io/<nombre_del_proyecto>/<nombre_de_la_imagen>:<etiqueta>
   #+end_src

#+begin_src bash
docker build -t gcr.io/PROJECT_ID/my-app .
docker push gcr.io/PROJECT_ID/my-app
#+end_src

** TODO Deploy docker imagen on GKE
Luego, para desplegar el contenedor en el cluster GKE, necesitarías crear un archivo de configuración de Kubernetes y aplicarlo con kubectl apply -f.

*** Deploy kubectl
#+begin_src yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-fastapi-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: model-fastapi-deployment
  template:
    metadata:
      labels:
        app: model-fastapi-deployment
    spec:
      containers:
        - name: model-fastapi
          image: gcr.io/sre-gcp-394115/fastapi-app:latest"
          imagePullPolicy: Always
          ports:
            - name: fastapi-port
              containerPort: 8000

---
apiVersion: v1
kind: Service
metadata:
  name: model-fastapi-service
spec:
  selector:
    app: model-fastapi-deployment
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 80
      targetPort: fastapi-port

#+end_src


#+begin_src bash
kubectl apply -f deployment.yaml
#+end_src


*** deploy terraform

#+begin_src bash
provider "google" {
  project = var.project_id
  region  = var.region
  zone    = var.zone
}

data "google_client_config" "default" {}

# GKE Cluster
resource "google_container_cluster" "small_cluster" {
  name                     = "small-cluster-k8s"
  location                 = "us-central1-f"
  initial_node_count       = 1
  remove_default_node_pool = true

  master_auth {
    client_certificate_config {
      issue_client_certificate = false
    }
  }

  # master_authorized_networks_config {
  #   cidr_blocks {
  #     cidr_block   = "0.0.0.0/0"
  #     display_name = "Any IP"
  #   }
  # }
}

# GKE Node Pool
resource "google_container_node_pool" "primary" {
  name       = "small-pool-k8s"
  location   = "us-central1-f"
  cluster    = google_container_cluster.small_cluster.name
  node_count = 1

  node_config {
    preemptible  = true
    machine_type = "e2-small"
    disk_size_gb = 10

    oauth_scopes = [
      "https://www.googleapis.com/auth/logging.write",
      "https://www.googleapis.com/auth/monitoring",
    ]
  }

  autoscaling {
    min_node_count = 2
    max_node_count = 3
  }

  management {
    auto_repair  = true
    auto_upgrade = true
  }
}
# Get Cluster data after it's created
data "google_container_cluster" "cluster" {
  name     = google_container_cluster.small_cluster.name
  location = "us-central1-f"
  depends_on = [
    google_container_cluster.small_cluster
  ]
}

# Kubernetes provider configuration using the cluster data
provider "kubernetes" {
#  host                   = data.google_container_cluster.cluster.endpoint
  host                   = "https://${google_container_cluster.small_cluster.endpoint}"
  token                  = data.google_client_config.default.access_token
  cluster_ca_certificate = base64decode(data.google_container_cluster.cluster.master_auth.0.cluster_ca_certificate)
}

# docker image deploy on GKE
resource "kubernetes_deployment" "app" {
  metadata {
    name = "fastapi-app-deployment"
    labels = {
      app = "fastapi-app"
    }
  }

  spec {
    replicas = 2

    selector {
      match_labels = {
        app = "fastapi-app"
      }
    }

    template {
      metadata {
        labels = {
          app = "fastapi-app"
        }
      }

      spec {
        container {
          image = "gcr.io/${var.project_id}/fastapi-app:latest" // reemplaza con la ruta a tu imagen
          name  = "fastapi-app"

          port {
            container_port = 8000 // reemplaza con el puerto que tu app escucha
          }
        }
      }
    }
  }
}

resource "kubernetes_service" "app" {
  metadata {
    name = "fastapi-app-service"
  }

  spec {
    selector = {
      app = kubernetes_deployment.app.metadata[0].labels.app
    }

    port {
      port        = 80
      target_port = 8000 // este debe ser el mismo puerto que definiste en tu Deployment
    }

    type = "LoadBalancer"
  }
}

# Cloud SQL Database
resource "google_sql_database_instance" "default" {
  name             = "postgres-instance"
  region           = var.region
  database_version = "POSTGRES_13"

  settings {
    tier = "db-f1-micro"
  }
}

resource "google_sql_database" "default" {
  name     = "my-postgres-database"
  instance = google_sql_database_instance.default.name
}

# Load Balancer
resource "google_compute_forwarding_rule" "default" {
  name                  = "lb-rule"
  load_balancing_scheme = "EXTERNAL"
  port_range            = "80"
  target                = google_compute_target_pool.default.self_link
}

resource "google_compute_target_pool" "default" {
  name = "target-pool"
  instances = [
    google_compute_instance.bastion_host.self_link
  ]
}

# # DNS Record
# resource "google_dns_record_set" "www" {
#   name         = "www.your-domain.com."
#   type         = "A"
#   ttl          = 300
#   managed_zone = "your-zone-name"
#   rrdatas      = [google_compute_forwarding_rule.default.IP_address]
# }

# Bastion Host
resource "google_compute_instance" "bastion_host" {
  name         = "bastion"
  machine_type = "e2-medium"
  zone         = var.zone

  boot_disk {
    initialize_params {
      image = var.bastion_image
    }
  }

  network_interface {
    network = "default"

    access_config {
      // Ephemeral IP
    }
  }

  service_account {
    scopes = [
      "https://www.googleapis.com/auth/logging.write",
      "https://www.googleapis.com/auth/monitoring",
      "https://www.googleapis.com/auth/pubsub",
      "https://www.googleapis.com/auth/service.management.readonly",
      "https://www.googleapis.com/auth/servicecontrol",
      "https://www.googleapis.com/auth/trace.append",
    ]
  }
}

#+end_src
